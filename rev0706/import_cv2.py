import cv2
import tensorflow as tf
import numpy as np
import time, threading, subprocess

import builtins, functools
print = functools.partial(builtins.print, flush=True)  # ëª¨ë“  print ì¦‰ì‹œ ì¶œë ¥


# ëª¨ë¸ ê²½ë¡œ
AGE_MODEL_PATH = "/home/linux/final/1_Age-VGG161.keras"
GENDER_MODEL_PATH = "/home/linux/final/1_Gender-ResNet1521.keras"

# â”€â”€â”€â”€â”€ Ollama í™˜ê²½ ê°ì§€ â”€â”€â”€â”€â”€
USE_PY_API = False
try:
    import ollama 
    _ = ollama.list()          # ë°ëª¬ í™•ì¸
    USE_PY_API = True
    print("[INFO] Ollama Python API ì‚¬ìš©")
except Exception as e:
    print("[WARN] Python API ì‚¬ìš© ë¶ˆê°€, CLI fallback:", e)

OLLAMA_CLI    = "/usr/local/bin/ollama"  # CLI ìœ„ì¹˜
OLLAMA_MODEL  = "gemma3:1b"
OLLAMA_TIMEOUT = 120  # sec
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ollama API í˜¸ì¶œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼)
def ask_ollama(prompt: str) -> str:
    """LLM í˜¸ì¶œ: Python API â†’ CLI ìˆœ"""
    if USE_PY_API:
        try:
            res = ollama.generate(model=OLLAMA_MODEL, prompt=prompt, stream=False)
            return res.get("response", "").strip()
        except Exception as e:
            return f"[API ì˜¤ë¥˜] {e}"
    # CLI fallback
    try:
        p = subprocess.run([OLLAMA_CLI, "run", OLLAMA_MODEL, prompt],
                           text=True, capture_output=True, timeout=OLLAMA_TIMEOUT)
        return p.stdout.strip() if p.returncode == 0 else f"[CLI ì˜¤ë¥˜] {p.stderr.strip()}"
    except Exception as e:
        return f"[CLI ì˜ˆì™¸] {e}"
    
# ëª¨ë¸ ë¡œë“œ
try:
    age_model = tf.keras.models.load_model(AGE_MODEL_PATH, compile=False)
    gender_model = tf.keras.models.load_model(GENDER_MODEL_PATH, compile=False)
    print("ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜, ëª¨ë¸ ì €ì¥ ì‹œ ì‚¬ìš©ëœ custom_objectsê°€ í•„ìš”í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()
                               
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
calling = False  # LLM í˜¸ì¶œ ì¤‘ë³µ ë°©ì§€ìš© í”Œë˜ê·¸
webcam_status_lock = threading.Lock() # ì›¹ìº  ìƒíƒœ ë³€ê²½ì„ ìœ„í•œ ë½
webcam_needs_closure = False # ì›¹ìº ì„ ë‹«ì•„ì•¼ í•¨ì„ ì•Œë¦¬ëŠ” í”Œë˜ê·¸
webcam_needs_reopen = False  # ì›¹ìº ì„ ë‹¤ì‹œ ì—´ì–´ì•¼ í•¨ì„ ì•Œë¦¬ëŠ” í”Œë˜ê·¸


# ollama_response_display ë³€ìˆ˜ì™€ ollama_response_lock ì œê±° (í™”ë©´ í‘œì‹œ ì•ˆ í•¨)

def worker(prompt):
    global calling
    global webcam_needs_closure
    global webcam_needs_reopen

    print("\nìƒê° ì¤‘â€¦ ì ì‹œë§Œìš”")
    
    # ì›¹ìº  ë‹«ê¸° ì‹ í˜¸ë¥¼ ë³´ëƒ„
    with webcam_status_lock:
        webcam_needs_closure = True

    # ì›¹ìº ì´ ë‹«í ë•Œê¹Œì§€ ëŒ€ê¸° (ë©”ì¸ ë£¨í”„ì—ì„œ ì›¹ìº ì„ ë‹«ì„ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼)
    while True:
        with webcam_status_lock:
            if not webcam_needs_closure: # ì›¹ìº  ë‹«ê¸° ì‘ì—…ì´ ì™„ë£Œë˜ë©´
                break
        time.sleep(0.01) # ì§§ê²Œ ëŒ€ê¸°

    reply = ask_ollama(prompt)       # â† Ollama í˜¸ì¶œ

    # ë‹µë³€ì„ í„°ë¯¸ë„ì—ë§Œ ì¶œë ¥
    print("\n" + reply + "\n")

    calling = False
    
    # ì›¹ìº  ë‹¤ì‹œ ì—´ê¸° ì‹ í˜¸ë¥¼ ë³´ëƒ„
    with webcam_status_lock:
        webcam_needs_reopen = True

    
# ì„¤ì •
IMAGE_SIZE = 224
gender_mapping = ["Male", "Female"]
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì–¼êµ´ íƒì§€ê¸° ë¡œë“œ (OpenCV ê¸°ë³¸ ì œê³µ HaarCascade ì‚¬ìš©)
try: 
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    if face_cascade.empty():
        print("ê²½ê³ : haarcascade_frontalface_default.xml íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ê²½ë¡œ: {cv2.data.haarcascades + 'haarcascade_frontal_face_default.xml'} í™•ì¸.")
except Exception as e:
    print(f"Haar Cascade ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

# ì›¹ìº  ì´ˆê¸° ì—´ê¸°
cap = cv2.VideoCapture(0) # 0, 1, 2 ë“±ìœ¼ë¡œ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
if not cap.isOpened():
    raise SystemExit("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨. ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¹´ë©”ë¼ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")

# FPS ê³ ì •ì„ ìœ„í•œ ì„¤ì •
padding, TARGET_FPS = 20, 20
FRAME_MS = int(1000 / TARGET_FPS)

# ì˜ˆì¸¡ ë¹ˆë„ ì„¤ì •
PREDICTION_INTERVAL_FRAMES = 50 
frame_count = 0
last_predictions = {} # ê° ì–¼êµ´ IDë³„ ë§ˆì§€ë§‰ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥

# Ollama í”„ë¡¬í”„íŠ¸ìš© ë³€ìˆ˜
detected_age = None
detected_gender = None

print("ìŠ¤í˜ì´ìŠ¤ë°” â†’ LLM ì¦‰ì‹œ í˜¸ì¶œ, q â†’ ì¢…ë£Œ")

while True:
    start = time.time() # í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„ ê¸°ë¡

    # ì›¹ìº  ë‹«ê¸° ìš”ì²­ ì²˜ë¦¬ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ìˆ˜í–‰)
    with webcam_status_lock:
        if webcam_needs_closure:
            if cap and cap.isOpened():
                cap.release()
                print("ì›¹ìº  ì¼ì‹œ ì •ì§€.")
            webcam_needs_closure = False # ë‹«ê¸° ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ
            # ì›¹ìº ì´ ë‹«í˜”ìœ¼ë‹ˆ ì´ í”„ë ˆì„ì—ì„œëŠ” ë” ì´ìƒ ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•ŠìŒ
            # ì´ ì§€ì ì—ì„œ ê²€ì€ í™”ë©´ì„ í‘œì‹œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
            black_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.imshow("Age & Gender Prediction", black_frame)
            key = cv2.waitKey(delay) & 0xFF # í‚¤ ì…ë ¥ ëŒ€ê¸° (ì°½ ì—…ë°ì´íŠ¸ ìœ ì§€)
            continue # ë‹¤ìŒ ë£¨í”„ ë°˜ë³µìœ¼ë¡œ ë„˜ì–´ê°€ì„œ ì›¹ìº  ì¬ê°œ ìš”ì²­ì„ ê¸°ë‹¤ë¦¼

    # ì›¹ìº  ë‹¤ì‹œ ì—´ê¸° ìš”ì²­ ì²˜ë¦¬ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œë§Œ ìˆ˜í–‰)
    with webcam_status_lock:
        if webcam_needs_reopen:
            if not (cap and cap.isOpened()): # ì›¹ìº ì´ ì‹¤ì œë¡œ ë‹«í˜€ìˆë‹¤ë©´ ë‹¤ì‹œ ì—´ê¸° ì‹œë„
                cap = cv2.VideoCapture(0)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

                if not cap.isOpened():
                    print("âŒ ì›¹ìº  ë‹¤ì‹œ ì—´ê¸° ì‹¤íŒ¨. ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                    # ì‹¤íŒ¨ ì‹œì—ë„ ì¬ì‹œë„ í”Œë˜ê·¸ë¥¼ í•´ì œí•˜ì—¬ ë£¨í”„ê°€ ê³„ì† ëŒê²Œ í•¨
                    webcam_needs_reopen = False 
                    # ì›¹ìº ì´ ì—´ë¦¬ì§€ ì•Šì•˜ìœ¼ë‹ˆ ì´ í”„ë ˆì„ì—ì„œëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•ŠìŒ
                    black_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    cv2.putText(black_frame, "ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨...", (100, 240),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                    cv2.imshow("Age & Gender Prediction", black_frame)
                    key = cv2.waitKey(delay) & 0xFF # í‚¤ ì…ë ¥ ëŒ€ê¸°
                    continue
                else:
                    print("ì›¹ìº  ì¬ê°œ.")
            webcam_needs_reopen = False # ì¬ì—´ê¸° ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ
            # ì›¹ìº ì´ ì—´ë ¸ìœ¼ë‹ˆ ë‹¤ìŒ ë£¨í”„ì—ì„œ ë°”ë¡œ í”„ë ˆì„ì„ ì½ë„ë¡ continue
            continue 

    # ì›¹ìº ì´ ì—´ë ¤ìˆì„ ë•Œë§Œ í”„ë ˆì„ì„ ì½ê³  ì²˜ë¦¬
    if cap and cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº  ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”. í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")
            break
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ì–¼êµ´ ê°ì§€ (ë§¤ í”„ë ˆì„ë§ˆë‹¤ ìˆ˜í–‰)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5) 

        # ê°€ì¥ í° ì–¼êµ´ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ì´ì™€ ì„±ë³„ì„ ì„¤ì • (ê°„ë‹¨í™”)
        main_face_area = 0
        main_face_id = -1

        for i, (x, y, w, h) in enumerate(faces):
            area = w * h
            if area > main_face_area:
                main_face_area = area
                main_face_id = i

            # ì˜ˆì¸¡ ë¹ˆë„ ë¡œì§ ì ìš©
            if frame_count % PREDICTION_INTERVAL_FRAMES == 0:
                # ì„¤ì •ëœ ê°„ê²©ë§ˆë‹¤ ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
                face = frame[y:y+h, x:x+w]
                
                if face.shape[0] == 0 or face.shape[1] == 0:
                    continue

                image = cv2.resize(face, (IMAGE_SIZE, IMAGE_SIZE))
                image = image / 255.0
                image = np.expand_dims(image, axis=0)

                try:
                    pred_age = age_model.predict(image, verbose=0)[0][0]
                    pred_gender = gender_model.predict(image, verbose=0)[0][0]
                    
                    age = int(pred_age)
                    gender = gender_mapping[int(np.round(pred_gender))]
                    
                    label = f"{gender}, Age: {age}"
                    last_predictions[i] = {'label': label, 'age': age, 'gender': gender} # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                except Exception as e:
                    label = "Prediction Error"
                    print(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì–¼êµ´ {i}): {e}")
                    last_predictions[i] = {'label': label, 'age': None, 'gender': None}
            else:
                # ì˜ˆì¸¡ ê°„ê²©ì´ ì•„ë‹ˆë¼ë©´, ë§ˆì§€ë§‰ìœ¼ë¡œ ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ ì‚¬ìš©
                if i in last_predictions:
                    label = last_predictions[i]['label']
                else:
                    label = "Detecting..." # ìƒˆë¡œ ë‚˜íƒ€ë‚¬ê±°ë‚˜ ì•„ì§ ì˜ˆì¸¡ë˜ì§€ ì•Šì€ ì–¼êµ´

            # ì–¼êµ´ ì£¼ìœ„ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸ ì¶”ê°€
            cv2.putText(frame, label, (x, y-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ê°€ì¥ í° ì–¼êµ´ì˜ ë‚˜ì´ì™€ ì„±ë³„ì„ Ollama í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ì €ì¥
        if main_face_id != -1 and main_face_id in last_predictions:
            detected_age = last_predictions[main_face_id].get('age')
            detected_gender = last_predictions[main_face_id].get('gender')
        else:
            detected_age = None
            detected_gender = None

        # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¦ê°€
        frame_count += 1
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        cv2.imshow("Age & Gender Prediction", frame)
    else:
        # ì›¹ìº ì´ ë‹«í˜€ìˆì„ ë•Œ (í˜¹ì€ ì•„ì§ ì—´ë¦¬ì§€ ì•Šì•˜ì„ ë•Œ) ê²€ì€ í™”ë©´ í‘œì‹œ
        black_frame = np.zeros((480, 640, 3), dtype=np.uint8)
        # ì›¹ìº ì´ ë‹«í˜”ë‹¤ëŠ” ë©”ì‹œì§€ í‘œì‹œ (ì´ë¯¸ 'Ollama ë‹µë³€ ì¤€ë¹„ ì¤‘...'ì´ í‘œì‹œë  ìˆ˜ ìˆìŒ)
        # ì´ ë¶€ë¶„ì€ í•„ìš”ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
        cv2.imshow("Age & Gender Prediction", black_frame)
    
    delay = max(1, FRAME_MS - int((time.time()-start)*1000))
    key = cv2.waitKey(delay) & 0xFF

    if key == ord('q'):
        break
    elif key == ord(' '):
        if calling:
            print("[INFO] ì´ë¯¸ ì¶”ì²œì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”!")
            continue                         # ìƒˆ ìŠ¤ë ˆë“œ ë§Œë“¤ì§€ ì•ŠìŒ
        if detected_gender and detected_age:
            calling = True
            llm_reply = "ğŸ”„ ì˜ì–‘ì œ ì¶”ì²œ ìƒì„± ì¤‘â€¦"
            prompt = (f"ë‚˜ëŠ” {detected_age} ì‚´ {detected_gender} ì„±ë³„ì˜ í•œêµ­ì¸ì´ì•¼."
                      f"í•„ìš”í•œ ì£¼ìš” ì˜ì–‘ì œ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ê³ ,"
                      f"ê° ì˜ì–‘ì œë¥¼ ê¶Œì¥í•˜ëŠ” ì´ìœ ë¥¼ 5ì¤„ë¡œ ì„¤ëª…í•´ ì¤˜. ë‹µë³€ì€ í•œêµ­ì–´ë¡œë§Œ í•´ì¤˜.") # í•œêµ­ì–´ ë‹µë³€ ìš”ì²­ ì¶”ê°€
            print("[LLM ìš”ì²­] ìƒì„± ìš”ì²­:", prompt) # CLIì— ìš”ì²­ í”„ë¡¬í”„íŠ¸ë„ ì¶œë ¥
            
            # worker ìŠ¤ë ˆë“œ ì‹œì‘ (ë°ëª¬ ìŠ¤ë ˆë“œë¡œ ì„¤ì •í•˜ì—¬ ë©”ì¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í•¨ê»˜ ì¢…ë£Œë˜ë„ë¡)
            threading.Thread(target=worker, args=(prompt,), daemon=True).start()
        else:
            print("[WARN] ë‚˜ì´ ë˜ëŠ” ì„±ë³„ ì •ë³´ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ Ollamaë¥¼ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ìì› í•´ì œ
if cap and cap.isOpened(): # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ì›¹ìº ì´ ì—´ë ¤ìˆìœ¼ë©´ ë‹«ê¸°
    cap.release()
cv2.destroyAllWindows()

print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ.")